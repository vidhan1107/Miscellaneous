{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c8ec22b3e787>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(5/144)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 3, 3, 4, 5, 8])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a = np.array([[1,4], [3,1], [5,3]])\n",
    "a = np.array([1,4, 3,1,8, 5,3])\n",
    "a = np.sort(a,axis=None)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "token_features = [0.0]*10\n",
    "print(token_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1' '2' 'abc' '2' '3' 'bd']\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import hstack\n",
    "a = np.array((1,2,\"abc\"))\n",
    "b = np.array((2,3,\"bd\"))\n",
    "z = np.hstack((a,b))\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 5, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "addlist = list([1,2,3]) + list([5,6,7])\n",
    "print(addlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3    False\n",
      "Name: val, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'Id':[1,2,3,4],\n",
    "                   'val':[2,5,np.nan,6]})\n",
    "print(df.val == np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello, TensorFlow!'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "hello = tf.constant('Hello, TensorFlow!')\n",
    "sess = tf.Session()\n",
    "print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "train_labels = np.array([0] * 5 + [1] * 5)\n",
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-ffa13d8088ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m df = pd.DataFrame({'x': ['Vid','Patel','Vijay']},\n\u001b[0m\u001b[0;32m      2\u001b[0m                   \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"x\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Y\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Z\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                   \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'123'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                  )\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#import ipdb; ipdb.set_trace() # debugging starts here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'x': ['Vid','Patel','Vijay']},\n",
    "                  columns = [\"x\", \"Y\", \"Z\"],\n",
    "                  index = list('123')\n",
    "                 )\n",
    "#import ipdb; ipdb.set_trace() # debugging starts here\n",
    "\n",
    "df['A'] = df['x'].str.len()\n",
    "df.drop(['Z'],axis=1, inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-00cf07b74dcd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[['2','3'], \"x\":\"Y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [10,5,3,6,8,3]\n",
    "lst.sort()\n",
    "print(lst)\n",
    "arr = [[14, 17, 12, 33, 44],   \n",
    "       [15, 6, 27, 8, 19],  \n",
    "       [23, 2, 54, 1, 4,]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile(arr,0, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import ipdb\n",
    "from IPython.core.debugger import set_trace\n",
    "def add_to_life_universe_everything(x):\n",
    "    answer = 42\n",
    "    set_trace()\n",
    "    answer += x\n",
    "    \n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_to_life_universe_everything(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ith value:  0\n",
      "Expected=1.000, Predicted=1.200\n",
      "ith value:  0\n",
      "Expected=3.000, Predicted=2.000\n",
      "ith value:  0\n",
      "Expected=3.000, Predicted=3.600\n",
      "ith value:  0\n",
      "Expected=2.000, Predicted=2.800\n",
      "ith value:  0\n",
      "Expected=5.000, Predicted=4.400\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import seed\n",
    "from random import randrange\n",
    "\n",
    "\n",
    "# Split a dataset into k folds\n",
    "def cross_validation_split(dataset, n_folds):\n",
    "    cross_validation_dataset = list()\n",
    "    dataset_copy = list(dataset)\n",
    "    fold_size = int(len(dataset_copy)/n_folds)\n",
    "    \n",
    "    for i in range(0, n_folds):\n",
    "        fold = list()\n",
    "        while len(fold) < fold_size:\n",
    "            index = randrange(len(dataset_copy))\n",
    "            fold.append(dataset_copy.pop(index))\n",
    "        cross_validation_dataset.append(fold)\n",
    "    return cross_validation_dataset\n",
    "\n",
    "# Calculate root mean squared error - metric to determine model performance\n",
    "def root_mean_squared_error(actual_y, predicted_y):\n",
    "    total_error = 0.0\n",
    "    for i in range(0, len(actual_y)):\n",
    "        error = predicted_y[i] - actual_y[i]\n",
    "        total_error += error**2\n",
    "    mean_error = total_error/float(len(actual_y))\n",
    "    return mean_error\n",
    "\n",
    "def predict(row, coefficients):\n",
    "    for i in range(0, len(row)-1):\n",
    "        y_hat = coefficients[i+1] * row[i] + coefficients[0]\n",
    "    return y_hat\n",
    "\n",
    "# Estimate linear regression coefficents using stochastic linear regression\n",
    "\"\"\"\n",
    "    epoch - number of times to run through training dataset and update coefficients\n",
    "    learning_rate - how fast/slow the coefficients are determined to acheive convergence\n",
    "    \n",
    "    For each row in training set, predict the value and get the error.\n",
    "    Then use the equation to update the coefficients\n",
    "\"\"\"\n",
    "def determine_sgd_coefficients(training_set, n_epoch, learning_rate):\n",
    "    coefficients = [0.0 for _ in range(0, len(training_set[0]))]\n",
    "    for _ in range(0, n_epoch):\n",
    "        for row in training_set:\n",
    "            y_hat = predict(row, coefficients)\n",
    "            error = y_hat - row[-1]\n",
    "            coefficients[0] = coefficients[0] - learning_rate * error\n",
    "            for i in range(0, len(row)-1):\n",
    "                coefficients[i+1] = coefficients[i+1] - learning_rate * error * row[i]\n",
    "    return coefficients\n",
    "\"\"\"\n",
    "    Evaluate algorithm's performance using a cross validation split.\n",
    "    Make n_fold partition of train set.\n",
    "    For each fold, make it a test set and others as train set and retrieve\n",
    "    the root mean squared error and store it.\n",
    "\"\"\"\n",
    "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
    "    folds = cross_validation_split(dataset, n_folds)\n",
    "    scores = list()\n",
    "    for fold in folds:\n",
    "        train_set = list(folds)\n",
    "        train_set.remove(fold)\n",
    "        train_set = sum(train_set, [])\n",
    "        test_set = list()\n",
    "        for row in fold:\n",
    "        row_copy = list(row)\n",
    "            test_set.append(row_copy)\n",
    "            row_copy[-1] = None\n",
    "        predicted = algorithm(train_set, test_set, *args)\n",
    "        actual = [row[-1] for row in fold]\n",
    "        rmse = root_mean_squared_error(actual, predicted)\n",
    "        scores.append(rmse)\n",
    "    return scores\n",
    "\n",
    "def linear_regression_sgd(train, test, learning_rate, n_epoch):\n",
    "    predictions = list()\n",
    "    coefficients = determine_sgd_coefficients(train, n_epoch, learning_rate)\n",
    "    for row in test:\n",
    "        y_hat = predict(row, coefficients)\n",
    "        predictions.append(y_hat)\n",
    "    return predictions\n",
    "\n",
    "# Importing the dataset\n",
    "dataset = pd.read_csv('winequality-white.csv')\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "dataset = sc.fit_transform(dataset)\n",
    "\n",
    "dataset = dataset.tolist()\n",
    "\n",
    "n_folds = 5\n",
    "learning_rate = 0.01\n",
    "n_epoch = 50\n",
    "scores = evaluate_algorithm(dataset, linear_regression_sgd, n_folds, learning_rate, n_epoch)\n",
    "print('Scores: %s' % scores)\n",
    "print('Mean RMSE: %.3f' % (sum(scores)/float(len(scores))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X=[1,2,3]\n",
    "X_np = np.array(X)\n",
    "Y_np = np.array([1,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(X, y, m_current=0, b_current=0, epochs=1000, learning_rate=0.0001):\n",
    "     N = float(len(y))\n",
    "     for i in range(epochs):\n",
    "          y_current = (m_current * X) + b_current\n",
    "          cost = sum([data**2 for data in (y-y_current)]) / N\n",
    "          m_gradient = -(2/N) * sum(X * (y - y_current))\n",
    "          b_gradient = -(2/N) * sum(y - y_current)\n",
    "          m_current = m_current - (learning_rate * m_gradient)\n",
    "          b_current = b_current - (learning_rate * b_gradient)\n",
    "     return m_current, b_current, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.15889562407619948, 0.0857337595807581, 0.30839617108406303)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regression(X_np, Y_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
