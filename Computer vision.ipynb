{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Detection with Haar Cascades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# face_cascade = cv2.CascadeClassifier('C:\\\\Users\\\\Admin\\\\AppliedAI\\\\Computer Vision\\\\haarcascades\\\\haarcascade_frontalface_default.xml')\n",
    "# eye_cascade = cv2.CascadeClassifier('C:\\\\Users\\\\Admin\\\\AppliedAI\\\\Computer Vision\\\\haarcascades\\\\haarcascade_eye.xml')\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_eye.xml')\n",
    "\n",
    "img = cv2.imread('vidhan.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_rects = face_cascade.detectMultiScale(img, scaleFactor=1.3, minNeighbors=10) \n",
    "\n",
    "for (x,y,w,h) in face_rects: \n",
    "    cv2.rectangle(img, (x,y), (x+w,y+h), (255,255,255), 20) \n",
    "    \n",
    "#     roi_gray = gray[y:y+h, x:x+w]\n",
    "#     eyes = eye_cascade.detectMultiScale(roi_gray, 1.03, 5, 0, (40,40))\n",
    "    \n",
    "#     for (ex,ey,ew,eh) in eyes:\n",
    "#         cv2.rectangle(img,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = cv2.VideoCapture(0)\n",
    "# count = 0\n",
    "# while (count<10):\n",
    "ret, frame = camera.read()\n",
    "gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "for (x,y,w,h) in faces:\n",
    "    img = cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "#         f = cv2.resize(gray[y:y+h, x:x+w], (200, 200))\n",
    "#         cv2.imwrite('./data/%s.pgm' % str(count), f)\n",
    "#         count += 1\n",
    "cv2.imshow(\"camera\", frame)\n",
    "\n",
    "cv2.waitKey(10000) \n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recognize face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images(path, sz=None):\n",
    "    c = 0\n",
    "    X,y = [], []\n",
    "    for dirname, dirnames, filenames in os.walk(path):\n",
    "        for subdirname in dirnames:\n",
    "            subject_path = os.path.join(dirname, subdirname)\n",
    "            for filename in os.listdir(subject_path):\n",
    "                try:\n",
    "                    if (filename == \".directory\"):\n",
    "                        continue\n",
    "                    filepath = os.path.join(subject_path, filename)\n",
    "                    im = cv2.imread(os.path.join(subject_path, filename),\n",
    "                    cv2.IMREAD_GRAYSCALE)\n",
    "                    # resize to given size (if given)\n",
    "                    if (sz is not None):\n",
    "                        im = cv2.resize(im, (200, 200))\n",
    "                    X.append(np.asarray(im, dtype=np.uint8))\n",
    "                    y.append(c)\n",
    "                except (errno, strerror):   # IOError\n",
    "                    print(\"I/O error({0}): {1}\".format(errno, strerror))\n",
    "                except:\n",
    "                    print(\"Unexpected error:\", sys.exc_info()[0])\n",
    "                    raise\n",
    "            c = c+1\n",
    "    return [X,y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_rec():\n",
    "    names = ['Joe', 'Jane', 'Jack']\n",
    "    if len(sys.argv) < 2:\n",
    "        print \"USAGE: facerec_demo.py </path/to/images>[</path/to/store/images/at>]\"\n",
    "        sys.exit()\n",
    "    [X,y] = read_images(sys.argv[1])\n",
    "    y = np.asarray(y, dtype=np.int32)\n",
    "    if len(sys.argv) == 3:\n",
    "        out_dir = sys.argv[2]\n",
    "    model = cv2.face.createEigenFaceRecognizer()\n",
    "    model.train(np.asarray(X), np.asarray(y))\n",
    "    camera = cv2.VideoCapture(0)\n",
    "    face_cascade =\n",
    "    cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_default.xml)\n",
    "    while (True):\n",
    "        read, img = camera.read()\n",
    "        faces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
    "        for (x, y, w, h) in faces:\n",
    "            img = cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            roi = gray[x:x+w, y:y+h]\n",
    "            try:\n",
    "                roi = cv2.resize(roi, (200, 200),\n",
    "                interpolation=cv2.INTER_LINEAR)\n",
    "                params = model.predict(roi)\n",
    "                print \"Label: %s, Confidence: %.2f\" % (params[0], params[1])\n",
    "                cv2.putText(img, names[params[0]], (x, y - 20),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, 255, 2)\n",
    "            except:\n",
    "                continue\n",
    "        cv2.imshow(\"camera\", img)\n",
    "        if cv2.waitKey(1000 / 12) & 0xff == ord(\"q\"):\n",
    "            break\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature detection using Harris Algo. (corner detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('images/chess_board.png')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# gray = np.float32(gray)\n",
    "dst = cv2.cornerHarris(gray, 2, 23, 0.04)\n",
    "img[dst>0.01 * dst.max()] = [0, 0, 255]\n",
    "while (True):\n",
    "    cv2.imshow('corners', img)\n",
    "    if cv2.waitKey(0) == ord(\"q\"):\n",
    "        break \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using SIFT Algo (detect blob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "imgpath = 'images/chess_board.png' #sys.argv[1]\n",
    "img = cv2.imread(imgpath)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "keypoints, descriptor = sift.detectAndCompute(gray,None)\n",
    "img = cv2.drawKeypoints(image=img, outImage=img, keypoints = keypoints, \n",
    "flags = cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINT, color = (51, 163, 236))\n",
    "cv2.imshow('sift_keypoints', img)\n",
    "while (True):\n",
    "    if cv2.waitKey(0) == ord(\"q\"):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SURF (Inspired by SIFT and faster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "imgpath = 'images/chess_board.png'   # sys.argv[1]\n",
    "img = cv2.imread(imgpath)\n",
    "alg = sys.argv[2]\n",
    "\n",
    "def fd(algorithm):\n",
    "    if algorithm == \"SIFT\":\n",
    "        return cv2.xfeatures2d.SIFT_create()\n",
    "    if algorithm == \"SURF\":\n",
    "        return cv2.xfeatures2d.SURF_create(float(4000)) # sys.argv[3]) if len(sys.argv) == 4 else 4000)\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "fd_alg = fd(\"SURF\")  # fd(alg)\n",
    "keypoints, descriptor = fd_alg.detectAndCompute(gray,None)\n",
    "img = cv2.drawKeypoints(image=img, outImage=img, keypoints = keypoints,\n",
    "flags = 4, color = (51, 163, 236))\n",
    "cv2.imshow('keypoints', img)\n",
    "while (True):\n",
    "    if cv2.waitKey(0) == ord(\"q\"):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.  BFMatcher (Brute Force)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "img1 = cv2.imread('images/vidhan.png',cv2.IMREAD_GRAYSCALE)\n",
    "img2 = cv2.imread('images/0.pgm', cv2.IMREAD_GRAYSCALE)\n",
    "orb = cv2.ORB_create()\n",
    "kp1, des1 = orb.detectAndCompute(img1,None)\n",
    "kp2, des2 = orb.detectAndCompute(img2,None)\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "matches = bf.match(des1,des2)\n",
    "matches = sorted(matches, key = lambda x:x.distance)\n",
    "img3 = cv2.drawMatches(img1,kp1,img2,kp2, matches[:40], img2,flags=2)\n",
    "plt.imshow(img3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. KNN Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img1 = cv2.imread('images/vidhan.png',cv2.IMREAD_GRAYSCALE)\n",
    "img2 = cv2.imread('images/0.pgm', cv2.IMREAD_GRAYSCALE)\n",
    "orb = cv2.ORB_create()\n",
    "kp1, des1 = orb.detectAndCompute(img1,None)\n",
    "kp2, des2 = orb.detectAndCompute(img2,None)\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "matches = bf.knnMatch(des1,des2, k=2)\n",
    "img3 = cv2.drawMatchesKnn(img1,kp1,img2,kp2, matches, img2,flags=2)\n",
    "plt.imshow(img3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FLANN Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img1 = cv2.imread('images/vidhan.png',cv2.IMREAD_GRAYSCALE)\n",
    "img2 = cv2.imread('images/0.pgm', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# create SIFT and detect/compute\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "kp1, des1 = sift.detectAndCompute(queryImage,None)\n",
    "kp2, des2 = sift.detectAndCompute(trainingImage,None)\n",
    "\n",
    "# FLANN matcher parameters\n",
    "FLANN_INDEX_KDTREE = 0\n",
    "indexParams = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "searchParams = dict(checks=50) # or pass empty dictionary\n",
    "flann = cv2.FlannBasedMatcher(indexParams,searchParams)\n",
    "matches = flann.knnMatch(des1,des2,k=2)\n",
    "# prepare an empty mask to draw good matches\n",
    "matchesMask = [[0,0] for i in xrange(len(matches))]\n",
    "# David G. Lowe's ratio test, populate the mask\n",
    "for i,(m,n) in enumerate(matches):\n",
    "    if m.distance < 0.7*n.distance:\n",
    "        matchesMask[i]=[1,0]\n",
    "drawParams = dict(matchColor = (0,255,0),\n",
    "singlePointColor = (255,0,0),\n",
    "matchesMask = matchesMask,\n",
    "flags = 0)\n",
    "resultImage = cv2.drawMatchesKnn(queryImage,kp1,trainingImage,kp2,matches,None,**drawParams)\n",
    "plt.imshow(resultImage,)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect moving object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "camera = cv2.VideoCapture(0)\n",
    "\n",
    "es = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (9,4))\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "background = None\n",
    "\n",
    "while (True):\n",
    "    ret, frame = camera.read()\n",
    "    if background is None:\n",
    "        background = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        background = cv2.GaussianBlur(background, (21, 21), 0)\n",
    "        continue\n",
    "        \n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray_frame = cv2.GaussianBlur(gray_frame, (21, 21), 0)\n",
    "    diff = cv2.absdiff(background, gray_frame)\n",
    "    diff = cv2.threshold(diff, 25, 255, cv2.THRESH_BINARY)[1]\n",
    "    diff = cv2.dilate(diff, es, iterations = 2)\n",
    "    image, cnts, hierarchy = cv2.findContours(diff.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    for c in cnts:\n",
    "        if cv2.contourArea(c) < 1500:\n",
    "            continue\n",
    "        \n",
    "    (x, y, w, h) = cv2.boundingRect(c)\n",
    "    cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    cv2.imshow(\"contours\", frame)\n",
    "    cv2.imshow(\"dif\", diff)\n",
    "\n",
    "    if cv2.waitKey(0) == ord(\"q\"):\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "camera.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BackgroundSubtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "bs = cv2.createBackgroundSubtractorKNN(detectShadows = True)\n",
    "camera = cv2.VideoCapture('first.mp4')\n",
    "while True:\n",
    "    ret, frame = camera.read()\n",
    "    fgmask = bs.apply(frame)\n",
    "    th = cv2.threshold(fgmask.copy(), 244, 255, cv2.THRESH_BINARY)[1]\n",
    "    dilated = cv2.dilate(th, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3)), iterations = 2)\n",
    "    image, contours, hier = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for c in contours:\n",
    "        if cv2.contourArea(c) > 1600:\n",
    "            (x,y,w,h) = cv2.boundingRect(c)\n",
    "            cv2.rectangle(frame, (x,y), (x+w, y+h), (255, 255, 0), 2)\n",
    "    cv2.imshow(\"mog\", fgmask)\n",
    "    cv2.imshow(\"thresh\", th)\n",
    "    cv2.imshow(\"detection\", frame)\n",
    "    if cv2.waitKey(0) == ord('q'):\n",
    "        break\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN in CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5.0, array([[-0.06419383, -0.13360272, -0.1681568 , -0.18708915,  0.0970564 ,\n",
      "         0.89237726,  0.05093023,  0.17537238,  0.13388439]],\n",
      "      dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "ann = cv2.ml.ANN_MLP_create()\n",
    "ann.setLayerSizes(np.array([9, 5, 9], dtype=np.uint8))\n",
    "ann.setTrainMethod(cv2.ml.ANN_MLP_BACKPROP)\n",
    "ann.train(np.array([[1.2, 1.3, 1.9, 2.2, 2.3, 2.9, 3.0, 3.2, 3.3]], dtype=np.float32), cv2.ml.ROW_SAMPLE,\n",
    "np.array([[0, 0, 0, 0, 0, 1, 0, 0, 0]], dtype=np.float32))\n",
    "print(ann.predict(np.array([[1.4, 1.5, 1.2, 2., 2.5, 2.8, 3., 3.1, 3.8]], dtype=np.float32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.zeros((3,3))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = np.random.randint(0, 256, 120000).reshape(300, 400)\n",
    "img = cv2.imread('vidhan.jpg')\n",
    "img[0,0] = [255, 255, 255]\n",
    "cv2.imwrite('ramdom.jpg', img)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cameraCapture = cv2.VideoCapture(0)\n",
    "fps = 30 # an assumption\n",
    "size = (int(cameraCapture.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cameraCapture.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "videoWriter = cv2.VideoWriter('MyOutputVid.avi', cv2.VideoWriter_fourcc('I','4','2','0'), fps, size)\n",
    "success, frame = cameraCapture.read()\n",
    "numFramesRemaining = 10 * fps - 1\n",
    "while success and numFramesRemaining > 0:\n",
    "videoWriter.write(frame)\n",
    "success, frame = cameraCapture.read()\n",
    "numFramesRemaining -= 1\n",
    "cameraCapture.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
